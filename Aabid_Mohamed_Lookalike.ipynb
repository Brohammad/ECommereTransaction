{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UWKueh5NdAZL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv('Customers.csv')\n",
        "products = pd.read_csv('Products.csv')\n",
        "transactions = pd.read_csv('Transactions.csv')"
      ],
      "metadata": {
        "id": "ZDe2uaU5dKEx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets\n",
        "merged_data = pd.merge(transactions, customers, on='CustomerID')\n",
        "merged_data = pd.merge(merged_data, products, on='ProductID')\n",
        "\n",
        "# Create customer profiles\n",
        "customer_profiles = merged_data.groupby('CustomerID').agg({\n",
        "    'TotalValue': 'sum',\n",
        "    'Quantity': 'sum',\n",
        "    'Region': 'first',\n",
        "    'Category': lambda x: x.mode()[0]  # Most purchased category\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "S18uLfcudTsY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "encoder = OneHotEncoder()\n",
        "encoded_features = encoder.fit_transform(customer_profiles[['Region', 'Category']]).toarray()\n",
        "\n",
        "# Normalize numeric features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(customer_profiles[['TotalValue', 'Quantity']])\n",
        "\n",
        "# Combine features\n",
        "features = np.hstack([scaled_features, encoded_features])"
      ],
      "metadata": {
        "id": "6mwEqCi7dfs4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute similarity matrix\n",
        "similarity_matrix = cosine_similarity(features)\n",
        "\n",
        "# Function to get top 3 lookalikes\n",
        "def get_lookalikes(customer_index, similarity_matrix, top_n=3):\n",
        "    similarities = similarity_matrix[customer_index]\n",
        "    top_indices = similarities.argsort()[-top_n-1:-1][::-1]\n",
        "    return [(customer_profiles.iloc[i]['CustomerID'], similarities[i]) for i in top_indices]\n",
        "\n",
        "# Generate lookalikes for the first 20 customers\n",
        "lookalike_map = {}\n",
        "for i in range(20):\n",
        "    customer_id = customer_profiles.iloc[i]['CustomerID']\n",
        "    lookalike_map[customer_id] = get_lookalikes(i, similarity_matrix)\n",
        "\n",
        "# Save to CSV\n",
        "import csv\n",
        "with open('Lookalike.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['CustomerID', 'LookalikeID', 'SimilarityScore'])\n",
        "    for cust_id, lookalikes in lookalike_map.items():\n",
        "        for lookalike_id, score in lookalikes:\n",
        "            writer.writerow([cust_id, lookalike_id, score])"
      ],
      "metadata": {
        "id": "aGouO6YqeXAu"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}